{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Mount the Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gb-ro3TbGxod",
        "outputId": "4c441c23-01d3-4fe6-efbc-085d1786798b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WY_kYM21GyQs"
      },
      "outputs": [],
      "source": [
        "! cd /content/drive/MyDrive/Github/CSE6250"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "o4KwTnu8F3pB"
      },
      "source": [
        "**Import Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_I24vCdZF0Hl",
        "outputId": "2ea025dd-6e2b-4e3a-8ea3-6ebfc62ca164"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import string\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk import word_tokenize\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "import numpy as np\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import datetime\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Flatten, Input, MaxPool2D\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Concatenate\n",
        "# from keras.optimizers import Adam\n",
        "# https://programmerah.com/keras-nightly-import-package-error-cannot-import-name-adam-from-keras-optimizers-29815/\n",
        "from keras.optimizers import Adam \n",
        "# https://stackoverflow.com/questions/62707558/importerror-cannot-import-name-adam-from-keras-optimizers\n",
        "# from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import StratifiedKFold\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "q2jEILEeGPHj"
      },
      "source": [
        "**Load Files**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Tf4D1QcOGHd_"
      },
      "outputs": [],
      "source": [
        "punctuations = list(string.punctuation)\n",
        "ip_txt_file = 'data/500_Reddit_users_posts_labels.csv'\n",
        "ip_feat_file = 'data/External_Features.csv'\n",
        "w2v_file = {'file': 'data/numberbatch-en.txt', 'is_binary': False}\n",
        "\n",
        "# Define results file\n",
        "op_file = \"data/Result_3+1-Label_Classification.tsv\"\n",
        "\n",
        "# severity_classes = {'Supportive': 0, 'Indicator': 1, 'Ideation': 2, 'Behavior': 3, 'Attempt': 4}\n",
        "#Collapse the supportive and indicator classes into a common class: control group.\n",
        "severity_classes = {'Supportive': 0, 'Indicator': 0, 'Ideation': 1, 'Behavior': 2, 'Attempt': 3}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "T8wMZHwiGM12"
      },
      "source": [
        "**Hyperparameters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5bU13IgGKWG",
        "outputId": "9d8d7d4e-73a0-40b8-aabe-d2e435d6a33d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "System Parameters:  {'emb_dim': 300, 'max_sent_len': 1500, 'str_padd': '@PADD', 'cross_val': 5}\n",
            "\n",
            "CNN Parameters:  {'no_filters': 100, 'kernels': [3, 4, 5], 'channel': 1, 'c_stride': (1, 300), 'pad': 'same', 'ip_shape': (1500, 300, 1), 'c_activ': 'relu', 'drop_rate': 0.3, 'dense_1_unit': 128, 'dense_2_unit': 128, 'dense_activ': 'relu', 'op_unit': 4, 'op_activ': 'softmax', 'l_rate': 0.001, 'loss': 'categorical_crossentropy', 'batch': 4, 'epoch': 10, 'verbose': 1}\n"
          ]
        }
      ],
      "source": [
        "sys_params = {'emb_dim': 300,\n",
        "              'max_sent_len': 1500,\n",
        "              'str_padd': '@PADD',\n",
        "              'cross_val': 5}\n",
        "\n",
        "cnn_params = {'no_filters': 100,\n",
        "              'kernels': [3, 4, 5],\n",
        "              'channel': 1,\n",
        "              'c_stride': (1, sys_params['emb_dim']),\n",
        "              'pad': 'same',\n",
        "              'ip_shape': (sys_params['max_sent_len'], sys_params['emb_dim'], 1),\n",
        "              'c_activ': 'relu',\n",
        "              'drop_rate': 0.3,\n",
        "              'dense_1_unit': 128,\n",
        "              'dense_2_unit': 128,\n",
        "              'dense_activ': 'relu',\n",
        "#               'op_unit': 5,             # 5-Label classification\n",
        "              'op_unit': 4,             # 4-Label classification\n",
        "              'op_activ': 'softmax',\n",
        "              'l_rate': 0.001,\n",
        "              'loss': 'categorical_crossentropy',\n",
        "              'batch': 4,\n",
        "              'epoch': 10,\n",
        "              'verbose': 1}\n",
        "\n",
        "intermediate_layer = 'flat_drop'    # for extracting features from CNN\n",
        "\n",
        "print ('\\nSystem Parameters: ', sys_params)\n",
        "print ('\\nCNN Parameters: ', cnn_params)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kQTmLMblK96w"
      },
      "source": [
        "**Read the input CSV file**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "zyq7mqJyGe6e"
      },
      "outputs": [],
      "source": [
        "def read_ip_file(ip_file):\n",
        "\n",
        "    padd = sys_params['str_padd']\n",
        "    max_len = sys_params['max_sent_len']\n",
        "\n",
        "    x_data, y_data = [], []\n",
        "\n",
        "    if ip_file:\n",
        "        with open(ip_file,\"r\") as csv_file:\n",
        "\n",
        "            # Exclude the first line (header)\n",
        "            csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "            next(csv_reader)\n",
        "\n",
        "            # Loop through each line\n",
        "            for row in csv_reader:\n",
        "\n",
        "                sent = row[1]\n",
        "\n",
        "                # Remove non-ascii characters\n",
        "                printable = set(string.printable)\n",
        "\n",
        "#               # Remove punctuation\n",
        "                # Remove punctuation and non-ascii characters\n",
        "                lst_tokens = [item.lower().strip(\"\".join(punctuations)) for item in word_tokenize(sent) if\n",
        "                              item not in punctuations and item not in printable]\n",
        "\n",
        "                # Strip the sentence if it exceeds the max length\n",
        "                if len(lst_tokens) > max_len:\n",
        "                    lst_tokens = lst_tokens[:max_len]\n",
        "\n",
        "                # Padd the sentence if the length is less than max length\n",
        "                elif len(lst_tokens) < max_len:\n",
        "                    for j in range(len(lst_tokens), max_len):\n",
        "                        lst_tokens.append(padd)\n",
        "\n",
        "                y_data.append(severity_classes[row[2].strip()])\n",
        "                x_data.append(lst_tokens)\n",
        "\n",
        "    return x_data, y_data"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9aTYmjHtK_ua"
      },
      "source": [
        "**Vectorize the input data using pretrained word2vec embedding lookup**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "LM2Ef4JCGhLs"
      },
      "outputs": [],
      "source": [
        "def vectorize_data(lst_input):\n",
        "\n",
        "    padd = sys_params['str_padd']\n",
        "    wv_size = sys_params['emb_dim']\n",
        "\n",
        "    # Load the pre-trained word2vec model\n",
        "    w2v_model = KeyedVectors.load_word2vec_format(w2v_file['file'], binary=w2v_file['is_binary'])\n",
        "\n",
        "    # Get the word2vec vocabulary\n",
        "    vocab =w2v_model.key_to_index\n",
        "    #\n",
        "    padding_zeros = np.zeros(wv_size, dtype=np.float32)\n",
        "\n",
        "    x_data = []\n",
        "\n",
        "    # Loop through each sentence\n",
        "    for sent in lst_input:\n",
        "        emb = []\n",
        "        for tok in sent:\n",
        "\n",
        "            # Zero-padding for padded tokens\n",
        "            if tok.lower() == padd:\n",
        "                emb.append(list(padding_zeros))\n",
        "\n",
        "            # Get the token embedding from the word2vec model\n",
        "            elif tok.lower() in vocab.keys():\n",
        "                emb.append(w2v_model[tok.lower()].astype(float).tolist())\n",
        "            # Zero-padding for out-of-vocab tokens\n",
        "            else:\n",
        "                emb.append(list(padding_zeros))\n",
        "\n",
        "        x_data.append(emb)\n",
        "\n",
        "    del w2v_model, vocab\n",
        "\n",
        "    return np.array(x_data)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ERn5jbX-LBp3"
      },
      "source": [
        "**Prepare the input data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "UtyvQmYQGiu0"
      },
      "outputs": [],
      "source": [
        "def read_data(ip_file):\n",
        "\n",
        "    # Read the input file\n",
        "    x_data, y_data = read_ip_file(ip_file)\n",
        "\n",
        "    # Vectorize the data\n",
        "    x_data = vectorize_data(x_data)\n",
        "\n",
        "    # # Reshape the data for CNN\n",
        "    x_data = x_data.reshape(x_data.shape[0], x_data.shape[1], x_data.shape[2], 1)  # last argument 1 indicates #channel\n",
        "\n",
        "    # Convert into numpy array\n",
        "    x_data, y_data = np.array(x_data), np.array(y_data)\n",
        "\n",
        "    return x_data, y_data"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "uMCWadrpLELM"
      },
      "source": [
        "**Read additional external features**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "bSbP9LaXGkOR"
      },
      "outputs": [],
      "source": [
        "def read_external_features(raw_data, raw_features):\n",
        "\n",
        "    user_ids, features = [], []\n",
        "\n",
        "    # Read the user ids from raw_data csv and append them to \"user_ids\" list\n",
        "    with open(raw_data) as file:\n",
        "        for line in file:\n",
        "            split = line.strip().split(',')\n",
        "            user_ids.append(split[0])\n",
        "\n",
        "    with open(raw_features) as csv_file:\n",
        "        # Read the feature file\n",
        "        csvreader = csv.reader(csv_file, delimiter=',')\n",
        "        # Skip the header row\n",
        "        header = next(csvreader)\n",
        "        # Loop through each user feature row\n",
        "        for row in csvreader:\n",
        "            # Convert the feature score into float\n",
        "            scores = [float(value) for value in row[1:]]\n",
        "            # Append feature score list for each user to final features list\n",
        "            features.append(scores)\n",
        "\n",
        "    # Return numpy array of features\n",
        "    return np.array(features)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9cquxc_WLGCi"
      },
      "source": [
        "**CNN Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "DB5_-hSnGnEc"
      },
      "outputs": [],
      "source": [
        "def get_cnn_model():\n",
        "    seq_len = sys_params['max_sent_len']\n",
        "    emb_dim = sys_params['emb_dim']\n",
        "\n",
        "    l_ip = Input(shape=(seq_len, emb_dim, 1), dtype='float32')\n",
        "    lst_convfeat = []\n",
        "    for filter in cnn_params['kernels']:\n",
        "        l_conv = Conv2D(filters=cnn_params['no_filters'], kernel_size=(filter, emb_dim), strides=cnn_params['c_stride'],\n",
        "                        padding=cnn_params['pad'], data_format='channels_last', input_shape=cnn_params['ip_shape'],\n",
        "                        activation=cnn_params['c_activ'])(l_ip)\n",
        "        l_pool = MaxPool2D(pool_size=(seq_len, 1))(l_conv)\n",
        "        lst_convfeat.append(l_pool)\n",
        "\n",
        "    l_concat = Concatenate(axis=1)(lst_convfeat)\n",
        "    l_flat = Flatten()(l_concat)\n",
        "    l_drop = Dropout(rate=cnn_params['drop_rate'], name='flat_drop')(l_flat)\n",
        "\n",
        "    # l_dense1 = Dense(units=cnn_params['dense_1_unit'], activation=cnn_params['dense_activ'], name='dense_1')(l_flat)\n",
        "    # l_drop2 = Dropout(rate=cnn_params['drop_rate'])(l_dense1)\n",
        "\n",
        "    # l_dense2 = Dense(units=cnn_params['dense_2_unit'], activation=cnn_params['dense_activ'], name='dense_2')(l_drop2)\n",
        "\n",
        "    l_op = Dense(units=cnn_params['op_unit'], activation=cnn_params['op_activ'], name='cnn_op')(l_drop)\n",
        "\n",
        "    final_model = Model(l_ip, l_op)\n",
        "    final_model.compile(optimizer=Adam(learning_rate=cnn_params['l_rate']), loss=cnn_params['loss'], metrics=['accuracy'])    # 'categorical_crossentropy'\n",
        "\n",
        "    return final_model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "e_qlRj_6LKAg"
      },
      "source": [
        "**MLP Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Id5HvJKSGnr7"
      },
      "outputs": [],
      "source": [
        "# Returns a MLP model for final classification\n",
        "def get_mlp_model(ip_dim):\n",
        "\n",
        "    mlp_model = Sequential()\n",
        "\n",
        "    mlp_model.add(Dense(units=cnn_params['op_unit'], activation=cnn_params['op_activ'], name='classif_op',\n",
        "                            input_dim=ip_dim))\n",
        "\n",
        "    mlp_model.compile(optimizer=Adam(learning_rate=cnn_params['l_rate']), loss=cnn_params['loss'],\n",
        "                          metrics=['accuracy'])\n",
        "    return mlp_model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "l4NLu5ReLM5S"
      },
      "source": [
        "**Precision, Recall, F1-Score**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "XS6CHIRzGpDo"
      },
      "outputs": [],
      "source": [
        "# Compute Precision, Recall, and F1-score\n",
        "def get_prf1_score(y_true, y_pred):\n",
        "    tp, fp, fn = 0.0, 0.0, 0.0\n",
        "    for i in range(len(y_pred)):\n",
        "        if y_pred[i] == y_true[i]:\n",
        "            tp += 1\n",
        "        elif y_pred[i] > y_true[i]:\n",
        "            fp += 1\n",
        "        else:\n",
        "            fn += 1\n",
        "    if tp == 0:\n",
        "        tp = 1.0\n",
        "    if fp == 0:\n",
        "        fp = 1.0\n",
        "    if fn == 0:\n",
        "        fn  = 1.0\n",
        "    P = tp / (tp + fp)\n",
        "    R = tp / (tp + fn)\n",
        "    F = 2 * P * R / (P + R)\n",
        "    print ('\\nPrecision: {0}\\t Recall: {1}\\t F1-Score: {2}'.format(P, R, F))\n",
        "    return {'P': P, 'R': R, 'F': F}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "BOtVKy68LQZA"
      },
      "source": [
        "**Ordinal Error and Scores**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "z5rM8jJEGqvC"
      },
      "outputs": [],
      "source": [
        "def oe_score(y_true, y_pred):\n",
        "    oe_no=0\n",
        "    nt=len(y_pred)\n",
        "    for i in range(nt):\n",
        "        if abs(y_pred[i]-y_true[i])>1:\n",
        "            oe_no+=1\n",
        "    OE= oe_no/nt\n",
        "    print('OE:{}'.format(OE))\n",
        "    return {'OE': OE}  \n",
        "    \n",
        "def scores(ypred,ytest):\n",
        "    ypred = np.argmax(ypred, axis=-1)\n",
        "    ytest = np.argmax(ytest, axis=-1)\n",
        "    score = get_prf1_score(ytest, ypred)\n",
        "    oe=oe_score(ytest, ypred)\n",
        "    return(score,oe)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "noDhdQNmLdC3"
      },
      "source": [
        "**Training, Testing and Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7B0iMKqGtD4",
        "outputId": "df9da65d-1463-41ba-bd83-39f1734a6936"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running Stratified Cross Validation: 1/5...\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 1500, 300,   0           []                               \n",
            "                                1)]                                                               \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 1500, 1, 100  90100       ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 1500, 1, 100  120100      ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 1500, 1, 100  150100      ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 1, 1, 100)    0           ['conv2d[0][0]']                 \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 1, 1, 100)   0           ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 1, 1, 100)   0           ['conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 3, 1, 100)    0           ['max_pooling2d[0][0]',          \n",
            "                                                                  'max_pooling2d_1[0][0]',        \n",
            "                                                                  'max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 300)          0           ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " flat_drop (Dropout)            (None, 300)          0           ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " cnn_op (Dense)                 (None, 4)            1204        ['flat_drop[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 361,504\n",
            "Trainable params: 361,504\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 9s 6ms/step - loss: 1.2547 - accuracy: 0.4250\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 1.1174 - accuracy: 0.5600\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9470 - accuracy: 0.6600\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.8160 - accuracy: 0.7150\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.6406 - accuracy: 0.7950\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4540 - accuracy: 0.8925\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.3086 - accuracy: 0.9650\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.2272 - accuracy: 0.9775\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.1514 - accuracy: 0.9875\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.1302 - accuracy: 0.9900\n",
            "13/13 [==============================] - 1s 37ms/step\n",
            "4/4 [==============================] - 0s 14ms/step\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " classif_op (Dense)          (None, 4)                 1260      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,260\n",
            "Trainable params: 1,260\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 299.3584 - accuracy: 0.1750\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 17.0270 - accuracy: 0.3100\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 13.0522 - accuracy: 0.3550\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 11.3977 - accuracy: 0.3925\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 9.8054 - accuracy: 0.4225\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 8.8341 - accuracy: 0.4200\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 7.4333 - accuracy: 0.4825\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 6.8436 - accuracy: 0.4975\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 6.1342 - accuracy: 0.5350\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 5.0617 - accuracy: 0.5725\n",
            "\n",
            "Time elapsed in training CNN:  0:00:02.089171\n",
            "\n",
            "Evaluating on Test data...\n",
            "\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 9.5372 - accuracy: 0.4200\n",
            "loss :  9.537225723266602\n",
            "accuracy :  0.41999998688697815\n",
            "4/4 [==============================] - 0s 2ms/step\n",
            "\n",
            "Precision: 0.9130434782608695\t Recall: 0.4375\t F1-Score: 0.5915492957746479\n",
            "OE:0.22\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.95      0.61        42\n",
            "           1       0.29      0.06      0.10        34\n",
            "           2       0.00      0.00      0.00        15\n",
            "           3       0.00      0.00      0.00         9\n",
            "\n",
            "    accuracy                           0.42       100\n",
            "   macro avg       0.18      0.25      0.18       100\n",
            "weighted avg       0.29      0.42      0.29       100\n",
            "\n",
            "\n",
            "Precision: 0.8888888888888888\t Recall: 0.6021505376344086\t F1-Score: 0.717948717948718\n",
            "OE:0.1\n",
            "\n",
            "Running Stratified Cross Validation: 2/5...\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 1500, 300,   0           []                               \n",
            "                                1)]                                                               \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 1500, 1, 100  90100       ['input_2[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 1500, 1, 100  120100      ['input_2[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 1500, 1, 100  150100      ['input_2[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 1, 1, 100)   0           ['conv2d_3[0][0]']               \n",
            "                                                                                                  \n",
            " max_pooling2d_4 (MaxPooling2D)  (None, 1, 1, 100)   0           ['conv2d_4[0][0]']               \n",
            "                                                                                                  \n",
            " max_pooling2d_5 (MaxPooling2D)  (None, 1, 1, 100)   0           ['conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 3, 1, 100)    0           ['max_pooling2d_3[0][0]',        \n",
            "                                                                  'max_pooling2d_4[0][0]',        \n",
            "                                                                  'max_pooling2d_5[0][0]']        \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)            (None, 300)          0           ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " flat_drop (Dropout)            (None, 300)          0           ['flatten_1[0][0]']              \n",
            "                                                                                                  \n",
            " cnn_op (Dense)                 (None, 4)            1204        ['flat_drop[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 361,504\n",
            "Trainable params: 361,504\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 1.2457 - accuracy: 0.4500\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 1.1324 - accuracy: 0.5475\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9620 - accuracy: 0.6275\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.7686 - accuracy: 0.7175\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.5643 - accuracy: 0.8550\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4154 - accuracy: 0.9300\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.2878 - accuracy: 0.9625\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.1867 - accuracy: 0.9850\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.1368 - accuracy: 0.9925\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0991 - accuracy: 0.9975\n",
            "13/13 [==============================] - 0s 17ms/step\n",
            "4/4 [==============================] - 0s 14ms/step\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " classif_op (Dense)          (None, 4)                 1260      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,260\n",
            "Trainable params: 1,260\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 249.0579 - accuracy: 0.2550\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 15.5493 - accuracy: 0.3350\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 13.1353 - accuracy: 0.3625\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 11.3272 - accuracy: 0.3800\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 9.5324 - accuracy: 0.4500\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 9.1303 - accuracy: 0.4200\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 7.6024 - accuracy: 0.4875\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 6.4427 - accuracy: 0.4925\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 5.3384 - accuracy: 0.5300\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 4.7828 - accuracy: 0.5750\n",
            "\n",
            "Time elapsed in training CNN:  0:00:02.066982\n",
            "\n",
            "Evaluating on Test data...\n",
            "\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.5236 - accuracy: 0.3700\n",
            "loss :  6.523627281188965\n",
            "accuracy :  0.3700000047683716\n",
            "4/4 [==============================] - 0s 2ms/step\n",
            "\n",
            "Precision: 0.5138888888888888\t Recall: 0.5692307692307692\t F1-Score: 0.5401459854014599\n",
            "OE:0.36\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.62      0.55        42\n",
            "           1       0.71      0.15      0.24        34\n",
            "           2       0.21      0.27      0.24        15\n",
            "           3       0.09      0.22      0.13         9\n",
            "\n",
            "    accuracy                           0.37       100\n",
            "   macro avg       0.38      0.31      0.29       100\n",
            "weighted avg       0.49      0.37      0.36       100\n",
            "\n",
            "\n",
            "Precision: 0.8333333333333334\t Recall: 0.6179775280898876\t F1-Score: 0.7096774193548387\n",
            "OE:0.15\n",
            "\n",
            "Running Stratified Cross Validation: 3/5...\n",
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 1500, 300,   0           []                               \n",
            "                                1)]                                                               \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 1500, 1, 100  90100       ['input_3[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 1500, 1, 100  120100      ['input_3[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 1500, 1, 100  150100      ['input_3[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_6 (MaxPooling2D)  (None, 1, 1, 100)   0           ['conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " max_pooling2d_7 (MaxPooling2D)  (None, 1, 1, 100)   0           ['conv2d_7[0][0]']               \n",
            "                                                                                                  \n",
            " max_pooling2d_8 (MaxPooling2D)  (None, 1, 1, 100)   0           ['conv2d_8[0][0]']               \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 3, 1, 100)    0           ['max_pooling2d_6[0][0]',        \n",
            "                                                                  'max_pooling2d_7[0][0]',        \n",
            "                                                                  'max_pooling2d_8[0][0]']        \n",
            "                                                                                                  \n",
            " flatten_2 (Flatten)            (None, 300)          0           ['concatenate_2[0][0]']          \n",
            "                                                                                                  \n",
            " flat_drop (Dropout)            (None, 300)          0           ['flatten_2[0][0]']              \n",
            "                                                                                                  \n",
            " cnn_op (Dense)                 (None, 4)            1204        ['flat_drop[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 361,504\n",
            "Trainable params: 361,504\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 1.2679 - accuracy: 0.4275\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 1.1464 - accuracy: 0.5050\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9860 - accuracy: 0.6100\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.7811 - accuracy: 0.7525\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.5889 - accuracy: 0.8575\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4089 - accuracy: 0.9350\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.2965 - accuracy: 0.9525\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.1856 - accuracy: 0.9900\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.1383 - accuracy: 0.9950\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0927 - accuracy: 0.9950\n",
            "13/13 [==============================] - 0s 17ms/step\n",
            "4/4 [==============================] - 0s 14ms/step\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " classif_op (Dense)          (None, 4)                 1260      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,260\n",
            "Trainable params: 1,260\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 83.0458 - accuracy: 0.3525\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 33.7293 - accuracy: 0.3525\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 13.6255 - accuracy: 0.3850\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 10.5411 - accuracy: 0.4300\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 10.6023 - accuracy: 0.4450\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 8.2417 - accuracy: 0.4775\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 7.6202 - accuracy: 0.5575\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 6.7402 - accuracy: 0.5625\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 6.2834 - accuracy: 0.5525\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 5.5896 - accuracy: 0.5800\n",
            "\n",
            "Time elapsed in training CNN:  0:00:02.079404\n",
            "\n",
            "Evaluating on Test data...\n",
            "\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 8.8023 - accuracy: 0.3100\n",
            "loss :  8.802252769470215\n",
            "accuracy :  0.3100000023841858\n",
            "4/4 [==============================] - 0s 2ms/step\n",
            "\n",
            "Precision: 0.36904761904761907\t Recall: 0.6595744680851063\t F1-Score: 0.4732824427480916\n",
            "OE:0.38\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.24      0.37        41\n",
            "           1       0.39      0.49      0.43        35\n",
            "           2       0.50      0.07      0.12        15\n",
            "           3       0.07      0.33      0.12         9\n",
            "\n",
            "    accuracy                           0.31       100\n",
            "   macro avg       0.43      0.28      0.26       100\n",
            "weighted avg       0.53      0.31      0.33       100\n",
            "\n",
            "\n",
            "Precision: 0.8135593220338984\t Recall: 0.5393258426966292\t F1-Score: 0.6486486486486486\n",
            "OE:0.13\n",
            "\n",
            "Running Stratified Cross Validation: 4/5...\n",
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_4 (InputLayer)           [(None, 1500, 300,   0           []                               \n",
            "                                1)]                                                               \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 1500, 1, 100  90100       ['input_4[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 1500, 1, 100  120100      ['input_4[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 1500, 1, 100  150100      ['input_4[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_9 (MaxPooling2D)  (None, 1, 1, 100)   0           ['conv2d_9[0][0]']               \n",
            "                                                                                                  \n",
            " max_pooling2d_10 (MaxPooling2D  (None, 1, 1, 100)   0           ['conv2d_10[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_11 (MaxPooling2D  (None, 1, 1, 100)   0           ['conv2d_11[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 3, 1, 100)    0           ['max_pooling2d_9[0][0]',        \n",
            "                                                                  'max_pooling2d_10[0][0]',       \n",
            "                                                                  'max_pooling2d_11[0][0]']       \n",
            "                                                                                                  \n",
            " flatten_3 (Flatten)            (None, 300)          0           ['concatenate_3[0][0]']          \n",
            "                                                                                                  \n",
            " flat_drop (Dropout)            (None, 300)          0           ['flatten_3[0][0]']              \n",
            "                                                                                                  \n",
            " cnn_op (Dense)                 (None, 4)            1204        ['flat_drop[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 361,504\n",
            "Trainable params: 361,504\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 1.2681 - accuracy: 0.4350\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 1.1193 - accuracy: 0.5450\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9573 - accuracy: 0.6425\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.7792 - accuracy: 0.7175\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.6089 - accuracy: 0.8250\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4208 - accuracy: 0.9100\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.2780 - accuracy: 0.9775\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.1857 - accuracy: 0.9900\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.1520 - accuracy: 0.9925\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.1088 - accuracy: 0.9950\n",
            "13/13 [==============================] - 0s 17ms/step\n",
            "4/4 [==============================] - 0s 14ms/step\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " classif_op (Dense)          (None, 4)                 1260      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,260\n",
            "Trainable params: 1,260\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 168.8050 - accuracy: 0.2425\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 26.3620 - accuracy: 0.3275\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 17.7001 - accuracy: 0.3450\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 14.3258 - accuracy: 0.3700\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 10.2598 - accuracy: 0.4050\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 8.6706 - accuracy: 0.4075\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 7.4666 - accuracy: 0.4425\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 5.7244 - accuracy: 0.4950\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 5.7067 - accuracy: 0.4600\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 4.2439 - accuracy: 0.5250\n",
            "\n",
            "Time elapsed in training CNN:  0:00:02.064352\n",
            "\n",
            "Evaluating on Test data...\n",
            "\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.2914 - accuracy: 0.4300\n",
            "loss :  5.291374683380127\n",
            "accuracy :  0.4300000071525574\n",
            "4/4 [==============================] - 0s 2ms/step\n",
            "\n",
            "Precision: 0.6417910447761194\t Recall: 0.5657894736842105\t F1-Score: 0.6013986013986014\n",
            "OE:0.15\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.54      0.55        41\n",
            "           1       0.39      0.56      0.46        34\n",
            "           2       0.17      0.12      0.14        16\n",
            "           3       0.00      0.00      0.00         9\n",
            "\n",
            "    accuracy                           0.43       100\n",
            "   macro avg       0.28      0.31      0.29       100\n",
            "weighted avg       0.39      0.43      0.40       100\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Precision: 0.9310344827586207\t Recall: 0.5625\t F1-Score: 0.7012987012987013\n",
            "OE:0.12\n",
            "\n",
            "Running Stratified Cross Validation: 5/5...\n",
            "Model: \"model_8\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)           [(None, 1500, 300,   0           []                               \n",
            "                                1)]                                                               \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 1500, 1, 100  90100       ['input_5[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 1500, 1, 100  120100      ['input_5[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 1500, 1, 100  150100      ['input_5[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_12 (MaxPooling2D  (None, 1, 1, 100)   0           ['conv2d_12[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_13 (MaxPooling2D  (None, 1, 1, 100)   0           ['conv2d_13[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_14 (MaxPooling2D  (None, 1, 1, 100)   0           ['conv2d_14[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate)    (None, 3, 1, 100)    0           ['max_pooling2d_12[0][0]',       \n",
            "                                                                  'max_pooling2d_13[0][0]',       \n",
            "                                                                  'max_pooling2d_14[0][0]']       \n",
            "                                                                                                  \n",
            " flatten_4 (Flatten)            (None, 300)          0           ['concatenate_4[0][0]']          \n",
            "                                                                                                  \n",
            " flat_drop (Dropout)            (None, 300)          0           ['flatten_4[0][0]']              \n",
            "                                                                                                  \n",
            " cnn_op (Dense)                 (None, 4)            1204        ['flat_drop[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 361,504\n",
            "Trainable params: 361,504\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 1.2474 - accuracy: 0.4625\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 1.1447 - accuracy: 0.5375\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9673 - accuracy: 0.6250\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.7746 - accuracy: 0.7075\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.6051 - accuracy: 0.8175\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4470 - accuracy: 0.8900\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.2941 - accuracy: 0.9600\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.2074 - accuracy: 0.9800\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.1412 - accuracy: 0.9925\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.1143 - accuracy: 0.9950\n",
            "13/13 [==============================] - 0s 17ms/step\n",
            "4/4 [==============================] - 0s 14ms/step\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " classif_op (Dense)          (None, 4)                 1260      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,260\n",
            "Trainable params: 1,260\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 303.7599 - accuracy: 0.3100\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 20.6669 - accuracy: 0.3175\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 14.4775 - accuracy: 0.3425\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 13.0511 - accuracy: 0.3575\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 11.3708 - accuracy: 0.3900\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 10.1724 - accuracy: 0.4100\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 8.3611 - accuracy: 0.4050\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 6.7683 - accuracy: 0.4850\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 5.4495 - accuracy: 0.5050\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 4.8772 - accuracy: 0.5350\n",
            "\n",
            "Time elapsed in training CNN:  0:00:02.053003\n",
            "\n",
            "Evaluating on Test data...\n",
            "\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 7.8863 - accuracy: 0.2300\n",
            "loss :  7.8863444328308105\n",
            "accuracy :  0.23000000417232513\n",
            "4/4 [==============================] - 0s 2ms/step\n",
            "\n",
            "Precision: 0.27380952380952384\t Recall: 0.5897435897435898\t F1-Score: 0.37398373983739835\n",
            "OE:0.38\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.24      0.33        41\n",
            "           1       0.25      0.03      0.05        34\n",
            "           2       0.21      0.69      0.32        16\n",
            "           3       0.04      0.11      0.06         9\n",
            "\n",
            "    accuracy                           0.23       100\n",
            "   macro avg       0.25      0.27      0.19       100\n",
            "weighted avg       0.33      0.23      0.21       100\n",
            "\n",
            "\n",
            "Precision: 0.8688524590163934\t Recall: 0.5760869565217391\t F1-Score: 0.6928104575163399\n",
            "OE:0.17\n",
            "=============3+1 Labels MLP model: 300 Features from CNN model + 14 External Features\n",
            "\n",
            "[{'P': 0.9130434782608695, 'R': 0.4375, 'F': 0.5915492957746479}, {'P': 0.5138888888888888, 'R': 0.5692307692307692, 'F': 0.5401459854014599}, {'P': 0.36904761904761907, 'R': 0.6595744680851063, 'F': 0.4732824427480916}, {'P': 0.6417910447761194, 'R': 0.5657894736842105, 'F': 0.6013986013986014}, {'P': 0.27380952380952384, 'R': 0.5897435897435898, 'F': 0.37398373983739835}]\n",
            "\n",
            " [{'OE': 0.22}, {'OE': 0.36}, {'OE': 0.38}, {'OE': 0.15}, {'OE': 0.38}]\n",
            "\n",
            "After Stratified Cross Validation Average Precision: 0.5423161109566041\t Recall: 0.5643676601487352\t F1-Score: 0.5160720130320399\t OE-Score:0.29799999999999993\n",
            "=============3+1 Labels SVM Linear: 300 Features from CNN model + 14 External Features\n",
            "\n",
            "[{'P': 0.9130434782608695, 'R': 0.4375, 'F': 0.5915492957746479}, {'P': 0.5138888888888888, 'R': 0.5692307692307692, 'F': 0.5401459854014599}, {'P': 0.36904761904761907, 'R': 0.6595744680851063, 'F': 0.4732824427480916}, {'P': 0.6417910447761194, 'R': 0.5657894736842105, 'F': 0.6013986013986014}, {'P': 0.27380952380952384, 'R': 0.5897435897435898, 'F': 0.37398373983739835}]\n",
            "\n",
            " [{'OE': 0.22}, {'OE': 0.36}, {'OE': 0.38}, {'OE': 0.15}, {'OE': 0.38}]\n",
            "\n",
            "After Stratified Cross Validation Average Precision: 0.8671336972062269\t Recall: 0.579608172988533\t F1-Score: 0.6940767889534494\t OE-Score:0.134\n",
            "Time Completing the tast:0.10794507251845466 hours\n"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "    import time\n",
        "    start_time=time.time()\n",
        "\n",
        "    with open(op_file, 'w') as of:\n",
        "        x_data, y_data = read_data(ip_txt_file)\n",
        "        ext_feature = read_external_features(ip_txt_file, ip_feat_file)\n",
        "        cv_count = 0\n",
        "        k_score = []\n",
        "        oescore = []       \n",
        "        kscore_svmln=[]\n",
        "        oescore_svmln=[]\n",
        "        \n",
        "        # Stratified cross-validation\n",
        "        skf = StratifiedKFold(n_splits=sys_params['cross_val'])\n",
        "        skf.get_n_splits(x_data, y_data)\n",
        "\n",
        "        # Run the model for each splits\n",
        "        for train_index, test_index in skf.split(x_data, y_data):\n",
        "            cv_count += 1\n",
        "            print ('\\nRunning Stratified Cross Validation: {0}/{1}...'.format(cv_count, sys_params['cross_val']))\n",
        "\n",
        "            x_train, x_test = x_data[train_index], x_data[test_index]\n",
        "            y_train, y_test = y_data[train_index], y_data[test_index]\n",
        "\n",
        "            # Convert the class labels into categorical\n",
        "            y_train, y_test = to_categorical(y_train), to_categorical(y_test)\n",
        "\n",
        "            # Reshape the data for CNN\n",
        "            x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
        "            x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 1)\n",
        "\n",
        "            # External features for this particular split\n",
        "            train_ext_feat, test_ext_feat = ext_feature[train_index], ext_feature[test_index]\n",
        "\n",
        "            # CNN model for training on the embedded text input\n",
        "            cnn_model = get_cnn_model()\n",
        "            print (cnn_model.summary())\n",
        "\n",
        "            # Train the model\n",
        "            cnn_model.fit(x=x_train, y=y_train, batch_size=cnn_params['batch'], epochs=cnn_params['epoch'], verbose=cnn_params['verbose'])\n",
        "            \n",
        "            # Trained model for extracting features from intermediate layer\n",
        "            model_feat_extractor = Model(inputs=cnn_model.input, outputs=cnn_model.get_layer(intermediate_layer).output)\n",
        "\n",
        "            # Get CNN gerated features\n",
        "            train_cnn_feat = model_feat_extractor.predict(x_train)\n",
        "            test_cnn_feat = model_feat_extractor.predict(x_test)\n",
        "\n",
        "            # Merge the CNN generated features with the external features\n",
        "            x_train_features = []\n",
        "            for index, cnn_feature in enumerate(train_cnn_feat):\n",
        "                tmp_feat = list(cnn_feature)\n",
        "                ###When run model without these 14 features, comment the following lines. So these 14 features won't be added to the input data\n",
        "                tmp_feat.extend(list(train_ext_feat[index]))\n",
        "                x_train_features.append(np.array(tmp_feat))\n",
        "\n",
        "            x_test_features = []\n",
        "            for index, cnn_feature in enumerate(test_cnn_feat):\n",
        "                tmp_feat = list(cnn_feature)\n",
        "                ###When run model without these 14 features, comment the following lines. So these 14 features won't be added to the input data\n",
        "                tmp_feat.extend(list(test_ext_feat[index]))\n",
        "                x_test_features.append(np.array(tmp_feat))\n",
        "\n",
        "            # Convert the list into numpy array\n",
        "            x_train_features = np.array(x_train_features)\n",
        "            x_test_features = np.array(x_test_features)\n",
        "\n",
        "            del train_cnn_feat, test_cnn_feat\n",
        "\n",
        "            # Get the MLP model for final classification\n",
        "            mlp_model = get_mlp_model(ip_dim = len(x_train_features[0]))\n",
        "            print (mlp_model.summary())\n",
        "\n",
        "            tc = time.time()\n",
        "\n",
        "            # Train the MLP model\n",
        "            mlp_model.fit(x=x_train_features, y=y_train, batch_size=cnn_params['batch'], epochs=cnn_params['epoch'], verbose=cnn_params['verbose'])\n",
        "                        \n",
        "            print ('\\nTime elapsed in training CNN: ', str(datetime.timedelta(seconds=time.time() - tc)))\n",
        "\n",
        "            print ('\\nEvaluating on Test data...\\n')\n",
        "            # # Print Loss and Accuracy\n",
        "            model_metrics = mlp_model.evaluate(x_test_features, y_test)\n",
        "\n",
        "            for i in range(len(model_metrics)):\n",
        "                print (mlp_model.metrics_names[i], ': ', model_metrics[i])\n",
        "\n",
        "            y_pred = mlp_model.predict(x_test_features)\n",
        "            \n",
        "            score,oe=scores(y_pred,y_test)\n",
        "            k_score.append(score)\n",
        "            oescore.append(oe)\n",
        "\n",
        "            y_pred = np.argmax(y_pred, axis=-1)\n",
        "            y_test_mlp = np.argmax(y_test, axis=-1)\n",
        "\n",
        "            # Scikit-learn classification report (P, R, F1, Support)\n",
        "            report = classification_report(y_test_mlp, y_pred)\n",
        "            print (report)\n",
        "\n",
        "            of.write('Cross_Val:\\n')\n",
        "            for i in range(len(y_pred)):\n",
        "                of.write('\\t'.join([str(y_test_mlp[i]), str(y_pred[i])]) + '\\n')\n",
        "           \n",
        "            ###SVM model--linear\n",
        "            ytrain_new=[key for ss in y_train for key,val in enumerate(ss) if val==1]\n",
        "            ytest_new=[key for ss in y_test for key,val in enumerate(ss) if val==1]\n",
        "\n",
        "            from sklearn.svm import SVC\n",
        "            model_svm_ln = SVC(kernel='linear', probability=True)\n",
        "            model_svm_ln.fit(x_train_features, np.array(ytrain_new))\n",
        "            y_pred_svmln=model_svm_ln.predict(x_test_features)\n",
        "            score_svmln = get_prf1_score(ytest_new, y_pred_svmln.tolist())\n",
        "            oe_svmln=oe_score(ytest_new, y_pred_svmln.tolist())\n",
        "            kscore_svmln.append(score_svmln)\n",
        "            oescore_svmln.append(oe_svmln)       \n",
        "            del x_train, y_train\n",
        "\n",
        "\n",
        "        print('=============3+1 Labels MLP model: 300 Features from CNN model + 14 External Features\\n')\n",
        "#         print('=============CNN model: 300 Features\\n')\n",
        "        print (k_score)        \n",
        "        print(\"\\n\",oescore)\n",
        "\n",
        "        avgP = np.average([score['P'] for score in k_score])\n",
        "        avgR = np.average([score['R'] for score in k_score])\n",
        "        avgF = np.average([score['F'] for score in k_score])\n",
        "        avgOE= np.average([score['OE'] for score in oescore])\n",
        "\n",
        "        print ('\\nAfter Stratified Cross Validation Average Precision: {0}\\t Recall: {1}\\t F1-Score: {2}\\t OE-Score:{3}'.format(avgP, avgR, avgF,avgOE))\n",
        "        \n",
        "        print('=============3+1 Labels SVM Linear: 300 Features from CNN model + 14 External Features\\n')\n",
        "\n",
        "        print (k_score)        \n",
        "        print(\"\\n\",oescore)\n",
        "\n",
        "        avgP_svmln = np.average([score['P'] for score in kscore_svmln])\n",
        "        avgR_svmln = np.average([score['R'] for score in kscore_svmln])\n",
        "        avgF_svmln = np.average([score['F'] for score in kscore_svmln])\n",
        "        avgOEs_svmln = np.average([score['OE'] for score in oescore_svmln])\n",
        "\n",
        "        print ('\\nAfter Stratified Cross Validation Average Precision: {0}\\t Recall: {1}\\t F1-Score: {2}\\t OE-Score:{3}'.format(avgP_svmln,avgR_svmln,avgF_svmln,avgOEs_svmln ))\n",
        "        end_time=time.time()\n",
        "        print(\"Time Completing the tast:{} hours\".format((end_time-start_time)/3600))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
